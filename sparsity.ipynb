{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity in Matrices\n",
    "\n",
    "Consider building ratings matrix where we are given with a large set of users who have watched a large set of movies. Naturally, all users watch a handful of movies and all movies are watched by only a handful of users based on their interests. And so, the ratings matrix which comprises of ratings given by a user to a movie, is going to be sparse.\n",
    "\n",
    "Performing matrix operations on such matrices like inverting the matrix, multiplying two matrices can be computationally costly given their size. However, as these matrices contain information in a small portion of complete data volume (rest are zeros), there are efficient ways of representing/storing this matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 2]\n",
      " [2 0 4 0 0]\n",
      " [0 0 0 5 0]]\n",
      "Sparsity: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,0,0,0,2], [2,0,4,0,0], [0,0,0,5,0]])\n",
    "print(arr)\n",
    "\n",
    "sparsity = np.sum(arr==0) / (arr.shape[0] * arr.shape[1])\n",
    "print('Sparsity:', sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrix Representations\n",
    "\n",
    "Some of the representations are as follows:\n",
    "\n",
    "1. **Compressed Sparse Row (CSR)** format: \n",
    "    1. Processes non-zero elements in data row-wise\n",
    "    2. Outputs three arrays:\n",
    "        1. Data: Non-zero values\n",
    "        2. Indices: Column indices\n",
    "        3. Indptr: \n",
    "            1. Index of starting element of each row\n",
    "            2. Last element is number of non-zero elements\n",
    "            3. Length - number of rows + 1\n",
    "            4. Is increasing in nature\n",
    "            5. For zero row, index of subsequent non-zero element\n",
    "\n",
    "2. **Compressed Sparse Column (CSC)** format: \n",
    "    1. Processes non-zero elements in data column-wise\n",
    "    2. Outputs three arrays:\n",
    "        1. Data: Non-zero values\n",
    "        2. Indices: Row indices\n",
    "        3. Indptr: \n",
    "            1. Index of starting element of each column\n",
    "            2. Last element is number of non-zero elements\n",
    "            3. Length - number of columns + 1\n",
    "            4. Is increasing in nature\n",
    "            5. For zero column, index of subsequent non-zero element\n",
    "\n",
    "3. **COOrdinate format (COO)** format: \n",
    "    1. Also called as triplet format\n",
    "    2. Typically after getting COO format, we convert to CSR/CSC matrix for faster algebraic operations.\n",
    "\n",
    "4. Another format: Three lists which need not be of same length comprising of the following:\n",
    "    1. <code>value</code>: Non-zero values\n",
    "    2. <code>column_idx</code>: Column indices of non-zero values \n",
    "    3. <code>row_idx</code>: Row indices from value list for starting element of each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These representations can be created by storing the data in form of key-value pairs in dictionary or lists of (values, row indices and column indices). However, the non-zero elements can be in any order, need not ordered row-wise or column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csr_representation(arr):\n",
    "    n_rows, n_cols = arr.shape\n",
    "    matrix_dict = {}\n",
    "\n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            if arr[row][col] != 0:\n",
    "                matrix_dict[(row, col)] = arr[row][col]\n",
    "                item = (row, col, arr[row][col])\n",
    "    return matrix_dict\n",
    "\n",
    "def get_csc_representation(arr):\n",
    "    n_rows, n_cols = arr.shape\n",
    "    matrix_dict = {}\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        for row in range(n_rows):\n",
    "            if arr[row][col] != 0:\n",
    "                matrix_dict[(row, col)] = arr[row][col]\n",
    "                item = (row, col, arr[row][col])\n",
    "    return matrix_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 1, (0, 4): 2, (1, 0): 2, (1, 2): 4, (2, 3): 5} \n",
      "\n",
      "Data: [1 2 2 4 5]\n",
      "Column Indices: [0 4 0 2 3]\n",
      "Row indices: [0 2 4 5]\n"
     ]
    }
   ],
   "source": [
    "csr_format = get_csr_representation(arr)\n",
    "print(csr_format,'\\n')\n",
    "\n",
    "row_idxs = np.array(list(csr_format.keys()))[:,0]\n",
    "col_idxs = np.array(list(csr_format.keys()))[:,1]\n",
    "values = list(csr_format.values())\n",
    "\n",
    "S = sp.csr_matrix((values, (row_idxs, col_idxs)))\n",
    "print('Data:', S.data)\n",
    "print('Column Indices:', S.indices)\n",
    "print('Row indices:', S.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 1, (1, 0): 2, (1, 2): 4, (2, 3): 5, (0, 4): 2} \n",
      "\n",
      "Data: [1 2 4 5 2]\n",
      "Column Indices: [0 1 1 2 0]\n",
      "Row indices: [0 2 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "csc_format = get_csc_representation(arr)\n",
    "print(csc_format, '\\n')\n",
    "\n",
    "row_idxs = np.array(list(csc_format.keys()))[:,0]\n",
    "col_idxs = np.array(list(csc_format.keys()))[:,1]\n",
    "values = list(csc_format.values())\n",
    "\n",
    "S = sp.csc_matrix((values, (row_idxs, col_idxs)))\n",
    "print('Data:', S.data)\n",
    "print('Column Indices:', S.indices)\n",
    "print('Row indices:', S.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csr_arrays(arr):\n",
    "    n_rows, n_cols = arr.shape\n",
    "    vals = []\n",
    "    col_idxs = []\n",
    "    row_idxs = []\n",
    "\n",
    "    val_idx = -1\n",
    "    for row in range(n_rows):\n",
    "        start = 1\n",
    "        start_idx = val_idx + 1\n",
    "        \n",
    "        for col in range(n_cols):\n",
    "            val = arr[row][col]\n",
    "\n",
    "            if val != 0:\n",
    "                vals.append(val)\n",
    "                val_idx += 1\n",
    "                col_idxs.append(col)\n",
    "\n",
    "                if start:\n",
    "                    start_idx = val_idx\n",
    "                    start = 0 \n",
    "        row_idxs.append(start_idx)\n",
    "    row_idxs.append(len(vals))\n",
    "    return vals, col_idxs, row_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [8, 5, 4, 7]\n",
      "Column Indices: [0, 1, 2, 2]\n",
      "Row indices: [0, 0, 1, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 0, 0],\n",
    "                [8, 0, 0],\n",
    "                [0, 5, 4],\n",
    "                [0, 0, 0],\n",
    "                [0, 0, 7]])\n",
    "\n",
    "vals, col_idxs, row_idxs = make_csr_arrays(arr)\n",
    "print('Data:', vals)\n",
    "print('Column Indices:', col_idxs)\n",
    "print('Row indices:', row_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML1M Dataset\n",
    "\n",
    "Now we will try to build sparse matrices and perform computations in sparse format for RecWalk algorithm. We observe that: \n",
    "1. Performing computations in sparse matrix format (CSR/CSC/COO) \n",
    "2. **Quantization:** Choosing efficient datatypes (low-precision formats) \n",
    "\n",
    "optimizes run-time and reduces memory overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "K = 20\n",
    "eta = 0.8\n",
    "n_iter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing movies data\n",
    "with open('ml-1m/movies.dat','r', encoding=\"ISO-8859-1\") as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "data = list(map(lambda x: x.split('::'), data))\n",
    "movies_df = pd.DataFrame(data, columns = ['movieID','title','genres'])\n",
    "movies_df['movieID'] = movies_df['movieID'].astype('int')\n",
    "\n",
    "# preprocessing ratings data\n",
    "with open('ml-1m/ratings.dat','r', encoding=\"ISO-8859-1\") as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "data = list(map(lambda x: x.split('::'), data))\n",
    "ratings_df = pd.DataFrame(data, columns = ['userID','movieID','rating','timestamp'])\n",
    "ratings_df[['userID','movieID','rating']] = ratings_df[['userID','movieID','rating']].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep the matrices precise, we will map userIDs and movieIDs to unique IDs starting from zero. This means if there are 6000 users with maximum userID as 9000, we have 6000 rows and not 9000 rows, one row per user. Likewise for movieIDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 6040\n",
      "Number of Movies: 3706\n"
     ]
    }
   ],
   "source": [
    "users_list = ratings_df['userID'].unique().tolist()\n",
    "movies_list = ratings_df['movieID'].unique().tolist()\n",
    "\n",
    "n_users = len(users_list)\n",
    "n_movies = len(movies_list)\n",
    "\n",
    "# relabelling userIDs\n",
    "userID2idx = dict(zip(users_list, range(n_users)))\n",
    "idx2userID = {v:k for k, v in userID2idx.items()}\n",
    "ratings_df['userID'].replace(userID2idx, inplace=True)\n",
    "\n",
    "# relabelling movieIDs\n",
    "movieID2idx = dict(zip(movies_list, range(n_movies)))\n",
    "idx2movieID = {v:k for k, v in movieID2idx.items()}\n",
    "ratings_df['movieID'].replace(movieID2idx, inplace=True)\n",
    "\n",
    "print('Number of Users:', n_users) \n",
    "print('Number of Movies:', n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrices(interaction_dict, ratings_dict):\n",
    "    values = []\n",
    "    row_idxs = []\n",
    "    col_idxs = []\n",
    "\n",
    "    userIDs = list(interaction_dict.keys())\n",
    "    for userID in tqdm(userIDs):\n",
    "        movieIDs = interaction_dict[userID].tolist()\n",
    "        ratings = ratings_dict[userID].tolist()\n",
    "        row_idxs += [userID] * len(movieIDs)\n",
    "        col_idxs += movieIDs\n",
    "        values += ratings\n",
    "\n",
    "    assert len(values) == len(row_idxs) == len(col_idxs)   \n",
    "    ratings_mat = sp.csr_matrix((values, (row_idxs, col_idxs)))\n",
    "    R = sp.csr_matrix(([1] * len(row_idxs), (row_idxs, col_idxs)))\n",
    "\n",
    "    # since W is not sparse, keeping it as numpy array\n",
    "    W = cosine_similarity(ratings_mat.T, ratings_mat.T, dense_output=True)\n",
    "    return R, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:00<00:00, 79982.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping users to their rated movies\n",
    "interaction_dict = dict(ratings_df.groupby('userID')['movieID'].apply(lambda x: np.array(x)))\n",
    "\n",
    "# mapping users to their ratings\n",
    "ratings_dict = dict(ratings_df.groupby('userID')['rating'].apply(lambda x: np.array(x)))\n",
    "\n",
    "R, W = get_sparse_matrices(interaction_dict, ratings_dict)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9746x9746 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2000418 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = sp.csr_matrix(np.zeros((n_users, n_users), dtype='bool'))\n",
    "M2 = sp.csr_matrix(np.zeros((n_movies, n_movies), dtype='bool'))\n",
    "AG = sp.vstack((sp.hstack((M1, R)), sp.hstack((R.T, M2))))\n",
    "\n",
    "# converting into CSR from COO format\n",
    "AG = sp.csr_matrix(AG)\n",
    "AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9746x9746 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2000418 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking transpose of CSR matrix converts it into CSC format\n",
    "one = sp.csr_matrix(np.ones(n_users + n_movies, dtype='bool')).transpose()\n",
    "\n",
    "values = (AG @ one).data\n",
    "row_idxs = list(range(AG.shape[0]))\n",
    "col_idxs = list(range(AG.shape[0]))\n",
    "\n",
    "# inverse calculated through LU decomposition\n",
    "# LU decomposition requires CSC format\n",
    "diag_sp_matrix = sp.csc_matrix((values, (row_idxs, col_idxs)))\n",
    "\n",
    "# inverse of diagonal matrix is diagonal matrix\n",
    "# expected to be sparse\n",
    "# CSC format\n",
    "inv_sp_matrix = sp.linalg.inv(diag_sp_matrix)\n",
    "\n",
    "# multiplication is commutative\n",
    "# can multiply CSC with CSR or CSR with CSC\n",
    "H = inv_sp_matrix @ AG\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9746x9746 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11319694 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_M_mat(W):\n",
    "    I = sp.csr_matrix(np.identity(n_users, dtype='bool'))\n",
    "    N1 = sp.csr_matrix(np.zeros((n_users, n_movies), dtype='bool'))\n",
    "    N2 = sp.csr_matrix(np.zeros((n_movies, n_users), dtype='bool'))\n",
    "\n",
    "    W_inf = max(np.sum(W, axis=1))\n",
    "    MI = W / W_inf + np.diag(1 - np.sum(W, axis=1) / W_inf)\n",
    "\n",
    "    M = sp.vstack((sp.hstack((I, N1)), sp.hstack((N2, MI))))\n",
    "    return M\n",
    "\n",
    "M = get_M_mat(W)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9746x9746 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13320112 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = alpha * H + (1 - alpha) * M\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Sparsity in following matrices:\n",
      "\n",
      "R: 4.47 %\n",
      "AG: 2.11 %\n",
      "H: 2.11 %\n",
      "M: 11.92 %\n",
      "P: 14.02 %\n"
     ]
    }
   ],
   "source": [
    "def calculate_non_sparsity(arr):\n",
    "    non_sparsity = len(arr.data) / (arr.shape[0] * arr.shape[1]) * 100\n",
    "    return non_sparsity\n",
    "\n",
    "print('Non-Sparsity in following matrices:\\n')\n",
    "print('R:', round(calculate_non_sparsity(R), 2), '%')\n",
    "print('AG:', round(calculate_non_sparsity(AG), 2), '%')\n",
    "print('H:', round(calculate_non_sparsity(H), 2), '%')\n",
    "print('M:', round(calculate_non_sparsity(M), 2), '%')\n",
    "print('P:', round(calculate_non_sparsity(P), 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recwalk_Kstep(P, K):\n",
    "    M1 = np.identity(n_users, dtype='bool')\n",
    "    M2 = np.zeros((n_users, n_movies), dtype='bool')\n",
    "    M3 = np.zeros((n_movies, n_users), dtype='bool')\n",
    "    M4 = np.zeros((n_movies, n_movies), dtype='bool')\n",
    "    teleport_dist = np.vstack((np.hstack((M1, M2)), np.hstack((M3, M4))))\n",
    "    \n",
    "    T = P.transpose().toarray()\n",
    "    state = teleport_dist.copy()\n",
    "    for _ in tqdm(range(K)):\n",
    "        state = T @ state\n",
    "    \n",
    "    recommendations = state[:n_users, n_users:]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(P_user, initial_state, n_iter):\n",
    "    new_initial_state = initial_state\n",
    "    NORM = []\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        final_state = np.dot(np.transpose(P_user), new_initial_state)\n",
    "        prev_initial_state = new_initial_state\n",
    "        new_initial_state = final_state\n",
    "        L1 = np.linalg.norm(new_initial_state-prev_initial_state, ord=1)\n",
    "        NORM.append(L1)\n",
    "\n",
    "        if i!=0 and (i+1)%5==0:\n",
    "            print(f'L1 Norm at {i+1} iteration..', L1)        \n",
    "        if np.allclose(new_initial_state, prev_initial_state):\n",
    "            print(f'Converged at {i+1} iterations..')\n",
    "            break\n",
    "    return final_state\n",
    "    \n",
    "def recwalk_PR(P, eta, n_iter):\n",
    "    M1 = np.identity(n_users, dtype='bool')\n",
    "    M2 = np.zeros((n_users, n_movies), dtype='bool')\n",
    "    M3 = np.zeros((n_movies, n_users), dtype='bool')\n",
    "    M4 = np.zeros((n_movies, n_movies), dtype='bool')\n",
    "    teleport_dist = np.vstack((np.hstack((M1, M2)), np.hstack((M3, M4))))\n",
    "\n",
    "    random_surf = np.ones((n_users + n_movies, n_users + n_movies), dtype='bool') / (n_users + n_movies)\n",
    "    \n",
    "    print('Running random walk..')\n",
    "    P_user = P.toarray() * eta + (1 - eta) * random_surf\n",
    "    limiting_state = random_walk(P_user, teleport_dist, n_iter)\n",
    "    \n",
    "    recommendations = limiting_state[:n_users, n_users:]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:20<00:00,  7.02s/it]\n"
     ]
    }
   ],
   "source": [
    "recommendations = recwalk_Kstep(P, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running random walk..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:39<07:25,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 5 iteration.. 0.1779545912263687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:28<06:45,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 10 iteration.. 0.02816183383724494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [02:17<05:56,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 15 iteration.. 0.004347350098805226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [03:06<04:59,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 20 iteration.. 0.0006879771982469931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [03:57<04:32, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 25 iteration.. 0.00010715391253270849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [04:52<03:48, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 30 iteration.. 1.6469422320759013e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [05:46<02:51, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 35 iteration.. 2.50671796068831e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [06:42<02:00, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 40 iteration.. 3.788464243166721e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [07:35<01:04, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm at 45 iteration.. 5.697842367180197e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [07:46<01:03, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 45 iterations..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = recwalk_PR(P, eta, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951daa5e1959839fcb325fff331f52e72634f7a1be998f6081ed7f433b63f1b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
